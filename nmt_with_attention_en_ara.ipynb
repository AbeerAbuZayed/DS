{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_with_attention_en_ara.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeerAbuZayed/Machine-Learning-projects/blob/master/nmt_with_attention_en_ara.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jmjh290raIky",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Neural machine translation with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1KC7aYLcdSBXG9-oJtGV252vMvx8HkQI2\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        " \n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnxXKDjq3jEL",
        "outputId": "59d7551f-2cdc-4f7c-eada-23e31946ff9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## Download and prepare the dataset\n",
        "\n",
        "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
        "\n",
        "```\n",
        "Study hard, and you'll succeed. \tادرس بجد و ستنجح\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "07fa8f81-c429-4043-d1d4-7ce9bf82cbb5",
        "id": "e3pBG1rE9nJG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'ara-eng.zip', origin='https://github.com/motazsaad/work-online-ds/raw/master/keras/rnn/ara-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/ara.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/motazsaad/work-online-ds/raw/master/keras/rnn/ara-eng.zip\n",
            "278528/270779 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rd0jw-eC3jEh",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?؛؟.!!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    if re.match(\"[a-zA-Z]+\", w):\n",
        "      # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "      w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "      w  = w.rstrip().strip()\n",
        "      # adding a start and an end token to the sentence\n",
        "      # so that the model know when to start and stop predicting.\n",
        "      w = '<start> ' + w + ' <end>'\n",
        "    else:\n",
        "      w = re.sub(r\"[ًٌٍَُِ]+\", \"\", w)\n",
        "      w = re.sub(r\"[^ء-ي0-9ﭐ-ﻼ?؟.!,،؛]+\", \" \", w)\n",
        "      w = w.rstrip().strip()\n",
        "      # adding a start and an end token to the sentence\n",
        "      # so that the model know when to start and stop predicting.\n",
        "      w = '<start> ' + w+ ' <end>'\n",
        "    \n",
        "    return w\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opI2GzOt479E",
        "outputId": "aa965178-e826-43e5-c531-7117697beb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "en_sentence = u\"Run!\"\n",
        "ara_sentence = u\"اركض ؟!\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(ara_sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> run ! <end>\n",
            "<start> اركض ؟ ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSA0g3bLloz",
        "colab_type": "code",
        "outputId": "30c8708a-de44-4b8b-d1ac-9a809546950b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Test\n",
        "string = 'Hi, how are you?\tمرحبًا، كيف حالك؟.'\n",
        "s= [preprocess_sentence(w) for w in string.split('\\t')]\n",
        "\n",
        "list(zip(s))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> hi , how are you ? <end>',), ('<start> مرحبا، كيف حالك ؟ . <end>',)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHn4Dct23jEm",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples): \n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTbSbBz55QtF",
        "outputId": "43825d4f-bda5-41e5-8d77-39ebe2c393ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "en, ara = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(ara[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> there are mothers and fathers who will lie awake after the children fall asleep and wonder how they ll make the mortgage , or pay their doctor s bills , or save enough for their child s college education . <end>\n",
            "<start> وهناك امهات واباء سيظلون مستيقظين بعد ان ينام اطفالهم، يتساءلون عن كيف سيسددون اقساط الرهن العقاري الذي اشترو به بيتهم، وكيف سيدفعون فواتير اطبايهم، او توفير ما يحتاجونه من مال لتسديد رسوم تسجيل ابنايهم في الجامعات . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEyXwflpwl-U",
        "colab_type": "code",
        "outputId": "9978dcff-09e8-45ec-f01d-4a0ac599f4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(en[100])\n",
        "print(ara[100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> tom left . <end>\n",
            "<start> لقد غادر توم . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OmMZQpdO60dt",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIOn8RCNDJXG",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAY9k49G3jE_",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster (optional)\n",
        "\n",
        "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnxC7q-j3jFD",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4QILQkOs3jFG",
        "outputId": "1eb1b620-c2b9-4e8a-8ff5-f13f8c95eb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8973 8973 2244 2244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJPmLZGMeD5q",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXukARTDd7MT",
        "outputId": "1b961c5c-283a-4d17-92b1-366df2d562c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "1410 ----> اترك\n",
            "31 ----> لي\n",
            "104 ----> بعض\n",
            "3073 ----> المثلجات\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "869 ----> save\n",
            "18 ----> me\n",
            "151 ----> some\n",
            "1039 ----> ice\n",
            "1165 ----> cream\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqHsArVZ3jFS",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qc6-NK1GtWQt",
        "outputId": "e6a803d6-8738-4be1-acc9-55719c971cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 39]), TensorShape([64, 42]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZ2rI24i3jFg",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    #add one extra layer\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    #self.gru = tf.keras.layers.LSTM(self.enc_units,\n",
        "    #                               return_sequences=True,\n",
        "    #                               return_state=True,\n",
        "    #                               recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60gSVh05Jl6l",
        "outputId": "5545b26b-61d0-4464-8645-3a54d81ab797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 39, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umohpBN2OM94",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k534zTHiDjQU",
        "outputId": "05e151e2-243c-4f49-dc89-d9a541fb3f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 39, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJ_B3mhW3jFk",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5UY8wko3jFp",
        "outputId": "163f3d69-8ee7-45a9-8b28-0a44baf653ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4066)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmTHr5iV3jFr",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zj8bXQTgNwrF",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hpObfY22IddU"
      },
      "source": [
        "## Training\n",
        "\n",
        "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
        "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
        "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
        "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "5. Use *teacher forcing* to decide the next input to the decoder.\n",
        "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
        "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sC9ArXSsVfqn",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddefjBMa3jF0",
        "outputId": "927bffdc-f45c-45d5-f8d4-39e0bb01e13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "EPOCHS =20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.6168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n",
        "\n",
        "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the *end token*.\n",
        "* And store the *attention weights for every time step*.\n",
        "\n",
        "Note: The encoder output is calculated only once for one input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbQpyYs13jF_",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5hQWlbN3jGF",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sl9zUHzg3jGI",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJpT9D5_OgP6",
        "colab": {}
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrAM0FDomq3E",
        "colab": {}
      },
      "source": [
        "translate(u' السلام عليكم')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWyay_Pw1AKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' أنا من مصر')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdKupVCOoslr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' كم عمرك الآن؟')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iKE4xoDo1e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' أنا أدرس الهندسة.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dpF-4Dno8m6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u'علم البيانات')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LN0mqbfpFyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' السلام ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrAZuib5pKBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' الحرب')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnjhSaMipRNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u'الأردن')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5AgTBJpVJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translate(u' تشرب الحليب')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i9QeyBHppT4",
        "colab_type": "code",
        "outputId": "d60bb02c-dfdd-4241-eade-d44ef104fb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "translate(u'من أين أنت؟')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> من اين انت ؟ <end>\n",
            "Predicted translation: where are you ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJwCAYAAAA5n02CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKKEGADAooQYAMCihBgAwKKEGADCo/w+ZVRcQdrKyOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiHXPRd7rAeJ",
        "colab_type": "code",
        "outputId": "21a3d52f-07a2-4980-f358-fccec907fdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "translate(u' من أنت؟ ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> من انت ؟ <end>\n",
            "Predicted translation: who are you ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAJwCAYAAAAOUYK2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwDAiHgAAEb+P+eME+HXY0ANAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-73EgU8HrnyW",
        "colab_type": "code",
        "outputId": "73c52e9f-cf14-449c-faf7-83f2b1f798e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "translate(u'سوف أشرب الحليب')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> سوف اشرب الحليب <end>\n",
            "Predicted translation: i ll have a glass . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAJyCAYAAAD0EqZrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJJaGR5JUivDI0lq9f8BO6KmkP7XxBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjWLuwKl8won",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}